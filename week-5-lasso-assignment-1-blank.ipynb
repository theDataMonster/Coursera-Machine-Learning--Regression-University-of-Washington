{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;32m1451556638 : INFO:     (initialize_globals_from_environment:282): Setting configuration variable GRAPHLAB_FILEIO_ALTERNATIVE_SSL_CERT_FILE to C:\\Users\\TDM\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\certifi\\cacert.pem\n",
      "\u001b[0m\u001b[1;32m1451556638 : INFO:     (initialize_globals_from_environment:282): Setting configuration variable GRAPHLAB_FILEIO_ALTERNATIVE_SSL_CERT_DIR to \n",
      "\u001b[0mThis non-commercial license of GraphLab Create is assigned to pratyushdvd@gmail.com and will expire on September 29, 2016. For commercial licensing options, visit https://dato.com/buy/.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-2544 - Server binary: C:\\Users\\TDM\\AppData\\Local\\Dato\\Dato Launcher\\lib\\site-packages\\graphlab\\unity_server.exe - Server log: C:\\Users\\TDM\\AppData\\Local\\Temp\\graphlab_server_1451556638.log.0\n",
      "[INFO] GraphLab Server Version: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']\n",
    ".19254432785, 661.7227177822587, 0.0, 15873.957259267981, 32.41022145125964, 690.1147733133256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2899.4202697498786, 30.011575302201045, 0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Linear regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 21613\n",
      "PROGRESS: Number of features          : 17\n",
      "PROGRESS: Number of unpacked features : 17\n",
      "PROGRESS: Number of coefficients    : 18\n",
      "PROGRESS: Starting Accelerated Gradient (FISTA)\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: | Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: Tuning step size. First iteration could take longer than subsequent iterations.\n",
      "PROGRESS: | 1         | 2        | 0.000002  | 1.484374     | 6962915.603493     | 426631.749026 |\n",
      "PROGRESS: | 2         | 3        | 0.000002  | 1.578125     | 6843144.200219     | 392488.929838 |\n",
      "PROGRESS: | 3         | 4        | 0.000002  | 1.609380     | 6831900.032123     | 385340.166783 |\n",
      "PROGRESS: | 4         | 5        | 0.000002  | 1.640631     | 6847166.848958     | 384842.383767 |\n",
      "PROGRESS: | 5         | 6        | 0.000002  | 1.687506     | 6869667.895833     | 385998.458623 |\n",
      "PROGRESS: | 6         | 7        | 0.000002  | 1.718761     | 6847177.773672     | 380824.455891 |\n",
      "PROGRESS: +-----------+----------+-----------+--------------+--------------------+---------------+\n",
      "PROGRESS: TERMINATED: Iteration limit reached.\n",
      "PROGRESS: This model may not be optimal. To improve it, consider increasing `max_iterations`.\n"
     ]
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[274873.0559504957,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8468.531086910072,\n",
       " 24.420720982445214,\n",
       " 350.0605533860648,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 842.0680348976282,\n",
       " 20.024722417091304,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_all.coefficients['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.25766285142e+14\n",
      "6.25766285362e+14\n",
      "6.25766286058e+14\n",
      "6.25766288257e+14\n",
      "6.25766295212e+14\n",
      "6.25766317206e+14\n",
      "6.25766386761e+14\n",
      "6.25766606749e+14\n",
      "6.25767302792e+14\n",
      "6.25769507644e+14\n",
      "6.25776517727e+14\n",
      "6.25799062845e+14\n",
      "6.25883719085e+14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for l1_penalty in np.logspace(1, 7, num=13):\n",
    "    model_all = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1_penalty,verbose= False)\n",
    "    pred=model_all.predict(validation)\n",
    "    rss=((((pred-validation['price'])**2)).sum())\n",
    "    print rss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.logspace(1, 7, num=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+08   1.27427499e+08   1.62377674e+08   2.06913808e+08\n",
      "   2.63665090e+08   3.35981829e+08   4.28133240e+08   5.45559478e+08\n",
      "   6.95192796e+08   8.85866790e+08   1.12883789e+09   1.43844989e+09\n",
      "   1.83298071e+09   2.33572147e+09   2.97635144e+09   3.79269019e+09\n",
      "   4.83293024e+09   6.15848211e+09   7.84759970e+09   1.00000000e+10]\n"
     ]
    }
   ],
   "source": [
    "print np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[564482.1368441753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "model_all_best = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10,verbose= False)\n",
    "print list(model_all_best.coefficients['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[25090.917367212027, 7789.177061100565, 847.5596869428746, 25234.209194458632, 39.03944596356858, 1117.3118955675666, -0.025686118239919543, 143.98899196976993, 20695.35923964388, 12466.690650291855, 568204.6445841154, 91066.94280879853, 6360.780926249808, 6139.2128056478905, 43.035829924605586, 118.94587495435255, 9.040401654020448, 48.61546730927457]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[26746.661936635508, 7743.979047849886, 822.358945250938, 25178.625930586946, 39.010718135253995, 1114.9107159232667, -0.018663073722782936, 142.51979784137154, 20545.867304697553, 12339.245250245602, 558930.2470718035, 90439.72185124886, 6288.009465538855, 6118.412320616764, 42.95755676813044, 117.99004260104351, 8.924085433195646, 46.56185624767168]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[28873.181016622384, 7691.047075686332, 790.9175796843559, 25115.27853451593, 38.98207881320865, 1112.2394146479912, -0.02473736058080104, 140.9458447508174, 20365.265896852696, 12181.186257705758, 547143.1801789048, 89651.6923915873, 6199.959965996101, 6094.1313865452685, 42.86718404798591, 116.7893252862552, 8.784328577071959, 43.95345985745588]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[31564.606473324213, 7618.567764636504, 750.1709548829197, 25026.177407617197, 38.935915253109734, 1108.3863193708141, -0.01774476275138433, 138.3853259458783, 20124.746720019702, 11975.49776169613, 532082.0756272506, 88631.04255545628, 6082.626008198676, 6060.6779112246695, 42.74031497907825, 115.24303664623336, 8.596902634509652, 40.62156230142574]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[34954.67174323056, 7515.377482147861, 696.7853594765766, 24894.556092358773, 38.856140639033626, 1102.5056436481414, 0.0, 133.90030719388716, 19795.93033118664, 11704.228054783032, 512800.5801387105, 87294.44208081363, 5922.041895353969, 6012.6238340951695, 42.55324369173369, 113.23793182751548, 8.337936513644951, 36.35851942869655]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[39314.615048616324, 7394.882889515538, 630.2530312218136, 24745.12178980744, 38.77550601691833, 1095.9906971335572, 0.0, 129.3716081662337, 19399.66700712912, 11367.957471896074, 488319.7480290306, 85626.78665609902, 5728.632165362397, 5956.871755685232, 42.34028399496754, 110.71867715722652, 8.028336789396947, 30.944030938872295]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[44909.33791831114, 7253.293148190762, 547.5924623737077, 24570.685895261584, 38.68228127230279, 1088.3818684231671, 0.0, 121.98711365252674, 18922.821613870317, 10954.471871806505, 457135.2571203196, 83487.12784485535, 5493.39678143304, 5890.403907087823, 42.076686259389646, 107.57670840450736, 7.65350461442852, 24.076198253079756]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[52030.03008056483, 7070.216615668923, 441.7750840911413, 24344.88205500959, 38.56150502802323, 1078.536813999621, 0.0, 112.95992577319848, 18308.867236448703, 10424.128529714346, 417398.76313595125, 80764.70244793859, 5191.188382056846, 5804.710901670971, 41.73926808864347, 103.55745460168669, 7.171559453202559, 15.317325464505155]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[61121.28202435141, 6842.360515558534, 307.90366016220366, 24063.60958749422, 38.40964739069744, 1066.2493764885905, 0.0, 100.19355929110365, 17539.440783134876, 9755.40223411253, 366774.0845431443, 77282.29881258898, 4811.239971932414, 5697.413131741469, 41.30948758268925, 98.47108255285787, 6.566249512807699, 4.170973622792697]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[72653.76283566156, 6537.498538782985, 135.20364887523834, 23681.23672270433, 38.19186469605985, 1049.3914965059957, 0.0, 83.22101625263917, 16527.63470379286, 8889.544638755358, 301854.63361377607, 72780.67609363608, 4313.382092011934, 5553.897040346681, 40.7353790102126, 91.90796363449786, 5.768965880750402, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[87298.82768111023, 6137.401722507512, 0.0, 23168.695279017622, 37.888523607022655, 1026.7096995183604, 0.0, 60.07198525926946, 15213.029420315976, 7778.835387674354, 217190.05177959352, 66808.73953276862, 3671.7283384428592, 5365.154612437338, 39.98228133899241, 83.36603089083604, 4.731371459705284, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[105843.80001578903, 5589.854102063284, 0.0, 22460.65593129862, 37.44845537114538, 995.1398159253142, 0.0, 29.061521925672103, 13469.249093949686, 6335.036737559216, 108231.30249081174, 59040.0488286964, 2826.4541225535186, 5110.134780587122, 38.967097464888575, 72.26234271807698, 3.3529134234043303, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[129178.71422833431, 4784.470900916188, 0.0, 21417.82247390828, 36.746069422594104, 947.9643280998356, 0.0, 0.0, 11067.154171923888, 4415.509049749234, 0.0, 48905.91595294178, 1667.8408359940804, 4746.515940254014, 37.51770516667074, 57.65691780061201, 1.4476431298936026, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[158796.2009043941, 3707.139629247276, 0.0, 19985.9978368454, 35.69739787089122, 882.788902804768, 0.0, 0.0, 7920.125236104686, 1926.9305157514896, 0.0, 32825.29786868613, 150.01433049590617, 4258.6630223491375, 35.527476868788746, 38.19405090777188, 0.0, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[196100.9378056226, 2181.574321070697, 0.0, 17962.696661157814, 34.14246565122554, 789.319789078241, 0.0, 0.0, 3665.930817596536, 0.0, 0.0, 11333.841030833106, 0.0, 3578.900400438109, 32.74320137175829, 12.795381135944636, 0.0, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[240309.75931983022, 0.0, 0.0, 13840.639957731408, 30.558358829776964, 592.1994692127664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2265.1205255597065, 27.48787265676394, 0.0, 0.0, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[291783.6780653794, 0.0, 0.0, 6104.325765458841, 23.170124302102437, 215.03093436538566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 18.407474015439522, 0.0, 0.0, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[352383.2203918056, 0.0, 0.0, 0.0, 11.508825781283852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.663435035929748, 0.0, 0.0, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[507987.9627437027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]>\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[564482.1368441753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]>\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in np.logspace(8, 10, num=20):\n",
    "    model_all = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1_penalty,verbose= False)\n",
    "    coeff=model_all['coefficients']['value']\n",
    "    print coeff.nnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_min =2.97635144e+09\n",
    "l1_penalty_max =3.79269019e+09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.97635144e+09   3.01931664e+09   3.06228183e+09   3.10524703e+09\n",
      "   3.14821223e+09   3.19117743e+09   3.23414262e+09   3.27710782e+09\n",
      "   3.32007302e+09   3.36303822e+09   3.40600341e+09   3.44896861e+09\n",
      "   3.49193381e+09   3.53489901e+09   3.57786420e+09   3.62082940e+09\n",
      "   3.66379460e+09   3.70675980e+09   3.74972499e+09   3.79269019e+09]\n"
     ]
    }
   ],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)\n",
    "print l1_penalty_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.66925692362e+14\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[196100.9378056226, 2181.574321070697, 0.0, 17962.696661157814, 34.14246565122554, 789.319789078241, 0.0, 0.0, 3665.930817596536, 0.0, 0.0, 11333.841030833106, 0.0, 3578.900400438109, 32.74320137175829, 12.795381135944636, 0.0, 0.0]>\n",
      "9.74019450085e+14\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[198563.24621808334, 2067.0151555582443, 0.0, 17810.387597798555, 34.021510305615884, 782.1823176948292, 0.0, 0.0, 3358.203305223814, 0.0, 0.0, 9876.737608119603, 0.0, 3528.2550088708495, 32.53723292119223, 11.05072885745476, 0.0, 0.0]>\n",
      "9.81188367942e+14\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[201025.56040541263, 1952.4764896096917, 0.0, 17658.089496535536, 33.900565354624526, 775.0454285495368, 0.0, 0.0, 3050.4721940384243, 0.0, 0.0, 8418.98705902193, 0.0, 3477.612166173268, 32.331265598515046, 9.306267213386809, 0.0, 0.0]>\n",
      "9.89328342459e+14\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[203443.60100002843, 1825.7886426921982, 0.0, 17487.492351087174, 33.76199379582756, 766.9631650720044, 0.0, 0.0, 2716.807621786021, 0.0, 0.0, 6944.366160803075, 0.0, 3421.3503525231667, 32.10532315753404, 7.513151240077715, 0.0, 0.0]>\n",
      "9.98783211266e+14\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[205805.89950145455, 1683.393441188375, 0.0, 17291.036028181912, 33.59899520820659, 757.631735463874, 0.0, 0.0, 2342.2083307967146, 0.0, 0.0, 5448.023508703517, 0.0, 3357.6713839074623, 31.850079862473553, 5.675104780051, 0.0, 0.0]>\n",
      "1.00847716702e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[208163.0754632091, 1539.5513689710174, 0.0, 17092.18196680723, 33.43373437667981, 748.1850483982429, 0.0, 0.0, 1963.784993533345, 0.0, 0.0, 3949.6853486213936, 0.0, 3293.308080311762, 31.592111748705104, 3.8330526398194786, 0.0, 0.0]>\n",
      "1.01829878055e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[210520.2514249636, 1395.709296753639, 0.0, 16893.32790543255, 33.26847354515303, 738.7383613326123, 0.0, 0.0, 1585.3616562699249, 0.0, 0.0, 2451.347188539233, 0.0, 3228.9447767160623, 31.334143634936726, 1.9910004995879744, 0.0, 0.0]>\n",
      "1.02824799221e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[212877.41334194763, 1251.868081591041, 0.0, 16694.475028890796, 33.10321369830053, 729.2917305532121, 0.0, 0.0, 1206.9405737677446, 0.0, 0.0, 953.0179560110532, 0.0, 3164.581856616472, 31.076177058220686, 0.14895933486268562, 0.0, 0.0]>\n",
      "1.03461690923e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[215235.60364366506, 1108.3695595585687, 0.0, 16496.236073166307, 32.93841184767406, 719.8684417855156, 0.0, 0.0, 829.5600647250927, 0.0, 0.0, 0.0, 0.0, 3100.359920213579, 30.818665290684812, 0.0, 0.0, 0.0]>\n",
      "1.03855473594e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[217598.30381490244, 966.3985002743709, 0.0, 16300.731946320315, 32.77565067773471, 710.5491844811639, 0.0, 0.0, 456.816087199674, 0.0, 0.0, 0.0, 0.0, 3036.766518244172, 30.563182489806817, 0.0, 0.0, 0.0]>\n",
      "1.04323723787e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[219929.8569701935, 815.2761922110091, 0.0, 16089.493189264538, 32.595397602048024, 700.4398943171266, 0.0, 0.0, 64.8212452204553, 0.0, 0.0, 0.0, 0.0, 2968.6998100380374, 30.289833484660797, 0.0, 0.0, 0.0]>\n",
      "1.04693748875e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[222253.19254432785, 661.7227177822587, 0.0, 15873.957259267981, 32.41022145125964, 690.1147733133256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2899.4202697498786, 30.011575302201045, 0.0, 0.0, 0.0]>\n",
      "1.05114762561e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[224545.1365013591, 496.98342997704214, 0.0, 15640.822913127087, 32.203934199389806, 678.9044193565222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2825.4694254035453, 29.715599775952782, 0.0, 0.0, 0.0]>\n",
      "1.05599273534e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[226807.0472336285, 322.0988884364551, 0.0, 15392.956522287555, 31.981755406895182, 666.9499040767615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2747.5278756524735, 29.40610788565725, 0.0, 0.0, 0.0]>\n",
      "1.06079953176e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[229077.8754477124, 149.41750849133973, 0.0, 15146.739275608525, 31.758637784209125, 655.0782487799131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2670.2506439548974, 29.097966305233044, 0.0, 0.0, 0.0]>\n",
      "1.0657076895e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[231334.9092206228, 0.0, 0.0, 14892.999487782487, 31.52877584284585, 642.8794167399659, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2590.981924492132, 28.781057387961518, 0.0, 0.0, 0.0]>\n",
      "1.06946433543e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[233587.84208595759, 0.0, 0.0, 14637.120281929754, 31.297068723025667, 630.5871994931391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2511.1399551993877, 28.46167227592114, 0.0, 0.0, 0.0]>\n",
      "1.07350454959e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[235832.55154166775, 0.0, 0.0, 14373.650392455014, 31.053226534522075, 617.8980219466142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2429.6800148115435, 28.138501649139545, 0.0, 0.0, 0.0]>\n",
      "1.07763277558e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[238074.13636151503, 0.0, 0.0, 14108.226217730988, 30.806777561657988, 605.1071231942883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2347.7607505775395, 27.814308951343662, 0.0, 0.0, 0.0]>\n",
      "1.08186759232e+15\n",
      "<bound method SArray.nnz of dtype: float\n",
      "Rows: 18\n",
      "[240309.75931983022, 0.0, 0.0, 13840.639957731408, 30.558358829776964, 592.1994692127664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2265.1205255597065, 27.48787265676394, 0.0, 0.0, 0.0]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\n",
    "    model_all = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1_penalty,verbose= False)\n",
    "    pred=model_all.predict(validation)\n",
    "    rss=((((pred-validation['price'])**2)).sum())\n",
    "    print rss\n",
    "    coeff=model_all['coefficients']['value']\n",
    "    print coeff.nnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.04693748875e+15\n",
    "<bound method SArray.nnz of dtype: float\n",
    "Rows: 18\n",
    "[222253.19254432785, 661.7227177822587, 0.0, 15873.957259267981, 32.41022145125964, 690.1147733133256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2899.4202697498786, 30.011575302201045, 0.0, 0.0, 0.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
